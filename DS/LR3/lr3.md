## Задание 1. Решающие пни
### Вопросы по заданию 1
1. На основе какого фактора будет построено решающее правило в корневой вершине?
Ответ: meanfreq

2. Чему равно оптимальное пороговое значение для данного фактора?
Получаем порог из визуализации дерева или из атрибутов модели
```
Оптимальное пороговое значение: 0.142
```

3. Сколько процентов наблюдений, для которых выполняется заданное в корневой вершине условие, содержится в обучающей выборке?

```
Процент наблюдений: 11.2
```
4. Сделайте предсказание и рассчитайте значение метрики accuracy на тестовой выборке.
```
Accuracy на тестовой выборке: 0.956
```
## Задание 2. Увеличим глубину дерева

### Вопросы по заданию 2
1. Из приведённых ниже факторов выберите те, что используются при построении данного дерева решений:
Ответ: A, B, D

2. Сколько листьев в построенном дереве содержат в качестве предсказания класс female? Нужно проанализировать визуализацию дерева.
Ответ: 2

3. Сделайте предсказание и рассчитайте значение метрики accuracy на тестовой выборке.
```
Accuracy на тестовой выборке: 0.962
```

## Задание 3. Дадим дереву решений б’ольшую свободу


### 1. Чему равна глубина полученного дерева решения?
```
Глубина дерева: 12
```
### 2. Чему равно количество листьев в полученном дереве решений?
```
Количество листьев: 54
```
### 3. Сделайте предсказание для обучающей и тестовой выборок и рассчитайте значение метрики accuracy на каждой из выборок
```
Accuracy на обучающей выборке: 1.000
Accuracy на тестовой выборке: 0.973
```
## Задание 4. Попробуем найти оптимальные внешние параметры модели дерева решений

### Задание сетки параметров
```
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [4, 5, 6, 7, 8, 9, 10],
    'min_samples_split': [3, 4, 5, 10]
}
```
### Задаём метод кросс-валидации
```cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # Добавлено перемешивание```

### Поиск оптимальных параметров с помощью GridSearchCV
```
grid_search = model_selection.GridSearchCV(tree.DecisionTreeClassifier(random_state=0), param_grid, scoring='accuracy', cv=cv, n_jobs=-1)
grid_search.fit(X_train, y_train)
```
#### 1. Какой критерий информативности использует наилучшая модель?
```
Лучший критерий информативности: gini
```
#### 2. Чему равна оптимальная найденная автоматически (с помощью GridSearchCV) максимальная глубина?
```
Оптимальная максимальная глубина: 5
```
#### 3. Чему равно оптимальное минимальное количество объектов, необходимое для разбиения?
```
Оптимальное минимальное количество объектов для разбиения: 4

```
#### 4. С помощью наилучшей модели сделайте предсказание отдельно для обучающей и тестовой выборок. Рассчитайте значение метрики accuracy на каждой из выборок.
```
Accuracy на обучающей выборке для лучшей модели: 0.987
Accuracy на тестовой выборке для лучшей модели: 0.975
```
## Задание 5. Для оптимального дерева решений, построенного в задании 4, найдите важность каждого из факторов

### Получение важности признаков
```feature_importances = best_model.feature_importances_```

### Выделение топ-3 наиболее важных факторов
```
Топ-3 наиболее важных факторов: ['meanfun', 'IQR', 'sfm']
```

